{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9839b50",
   "metadata": {},
   "source": [
    "# Inference Time Profiling\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook measures inference performance:\n",
    "\n",
    "1. **GPU Inference Time**: Time per image and FPS on GPU\n",
    "2. **CPU Inference Time**: Time per image and FPS on CPU\n",
    "3. **mAP Computation Time**: Full evaluation loop time\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Batch size = 1 (single image inference)\n",
    "- Warm-up runs to stabilize GPU/CPU\n",
    "- GPU synchronization for accurate timing\n",
    "- Multiple runs (N=100) for averaging\n",
    "- Separate timing for inference vs full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14abea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from models.maskrcnn_model import get_custom_maskrcnn\n",
    "from datasets.isaid_dataset import iSAIDDataset\n",
    "from training.trainer import collate_fn, create_datasets\n",
    "from training.transforms import get_transforms\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bfb7b",
   "metadata": {},
   "source": [
    "## 1. Configuration & W&B Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to W&B\n",
    "try:\n",
    "    # For Kaggle\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_key = user_secrets.get_secret(\"wandb_key\")\n",
    "    wandb.login(key=wandb_key)\n",
    "except:\n",
    "    # For local - assumes you've already run 'wandb login'\n",
    "    wandb.login()\n",
    "\n",
    "print(\"✓ Logged into W&B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "NUM_CLASSES = 16  # iSAID has 15 classes + background\n",
    "\n",
    "# W&B artifact configuration\n",
    "WANDB_ENTITY = \"marek-olnk-put-pozna-\"\n",
    "WANDB_PROJECT = \"isaid-custom-segmentation\"\n",
    "ARTIFACT_NAME = \"isaid-maskrcnn-final:v0\"\n",
    "\n",
    "# Dataset path\n",
    "DATA_ROOT = Path(\"/kaggle/input/isaid-patches\")  # Change for local\n",
    "if not DATA_ROOT.exists():\n",
    "    DATA_ROOT = project_root / \"data\" / \"iSAID_patches\"\n",
    "\n",
    "# Timing settings\n",
    "WARMUP_RUNS = 10\n",
    "TIMING_RUNS = 100\n",
    "EVAL_SUBSET_SIZE = 200  # Number of images for mAP timing\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"  W&B Artifact: {WANDB_ENTITY}/{WANDB_PROJECT}/{ARTIFACT_NAME}\")\n",
    "print(f\"  Data root: {DATA_ROOT}\")\n",
    "print(f\"  Warmup runs: {WARMUP_RUNS}\")\n",
    "print(f\"  Timing runs: {TIMING_RUNS}\")\n",
    "print(f\"  Eval subset size: {EVAL_SUBSET_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df240840",
   "metadata": {},
   "source": [
    "## 2. Download Model from W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model artifact from W&B\n",
    "print(\"Downloading model from W&B...\")\n",
    "run = wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY, job_type=\"timing\")\n",
    "artifact = run.use_artifact(f'{WANDB_ENTITY}/{WANDB_PROJECT}/{ARTIFACT_NAME}', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "print(f\"✓ Model downloaded to: {artifact_dir}\")\n",
    "\n",
    "# Set checkpoint path\n",
    "CHECKPOINT_PATH = Path(artifact_dir) / \"best_map_model.pth\"\n",
    "print(f\"  Checkpoint: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97911cc7",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"Creating model architecture...\")\n",
    "model = get_custom_maskrcnn(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    pretrained_backbone=False,\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "\n",
    "    # Extract model weights from checkpoint\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model_weights = checkpoint['model_state_dict']\n",
    "        epoch = checkpoint.get('epoch', 'unknown')\n",
    "        print(f\"  Checkpoint from epoch: {epoch}\")\n",
    "    else:\n",
    "        model_weights = checkpoint\n",
    "\n",
    "    model.load_state_dict(model_weights)\n",
    "    print(\"✓ Checkpoint loaded successfully\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "\n",
    "model.eval()\n",
    "print(\"\\n✓ Model ready for timing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da644cc",
   "metadata": {},
   "source": [
    "## 4. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "print(\"Loading validation dataset...\")\n",
    "val_dataset = iSAIDDataset(\n",
    "    root=DATA_ROOT,\n",
    "    split='val',\n",
    "    transforms=get_transforms(train=False)\n",
    ")\n",
    "\n",
    "# Get a single image for inference timing\n",
    "single_image, _ = val_dataset[0]\n",
    "print(f\"Single image shape: {single_image.shape}\")\n",
    "\n",
    "# Create subset for mAP timing\n",
    "subset_indices = list(range(min(EVAL_SUBSET_SIZE, len(val_dataset))))\n",
    "val_subset = Subset(val_dataset, subset_indices)\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"✓ Validation dataset loaded: {len(val_dataset)} images\")\n",
    "print(f\"✓ Subset for mAP timing: {len(val_subset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f416d7",
   "metadata": {},
   "source": [
    "## 5. GPU Inference Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GPU INFERENCE TIMING\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Move model and image to GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.to(device)\n",
    "    image = single_image.to(device)\n",
    "\n",
    "    # Warm-up\n",
    "    print(f\"\\nWarming up GPU ({WARMUP_RUNS} runs)...\")\n",
    "    for _ in range(WARMUP_RUNS):\n",
    "        with torch.no_grad():\n",
    "            _ = model([image])\n",
    "\n",
    "    # Timing runs with synchronization\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"Running {TIMING_RUNS} inference passes...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(TIMING_RUNS):\n",
    "        with torch.no_grad():\n",
    "            _ = model([image])\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Calculate metrics\n",
    "    time_per_image_gpu = elapsed_time / TIMING_RUNS\n",
    "    fps_gpu = 1 / time_per_image_gpu\n",
    "\n",
    "    print(f\"\\n✓ GPU Timing Complete\")\n",
    "    print(f\"  Total time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"  Time per image: {time_per_image_gpu*1000:.2f} ms\")\n",
    "    print(f\"  FPS: {fps_gpu:.2f}\")\n",
    "\n",
    "    gpu_results = {\n",
    "        'time_ms': time_per_image_gpu * 1000,\n",
    "        'fps': fps_gpu,\n",
    "        'total_time': elapsed_time\n",
    "    }\n",
    "else:\n",
    "    print(\"CUDA not available - skipping GPU timing\")\n",
    "    gpu_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f44152",
   "metadata": {},
   "source": [
    "## 6. CPU Inference Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CPU INFERENCE TIMING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n⚠️  Warning: CPU inference will be slow!\\n\")\n",
    "\n",
    "# Move model and image to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "image = single_image.to(device)\n",
    "\n",
    "# Warm-up\n",
    "print(f\"Warming up CPU ({WARMUP_RUNS} runs)...\")\n",
    "for _ in range(WARMUP_RUNS):\n",
    "    with torch.no_grad():\n",
    "        _ = model([image])\n",
    "\n",
    "# Timing runs (no synchronization needed for CPU)\n",
    "print(f\"Running {TIMING_RUNS} inference passes...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(TIMING_RUNS):\n",
    "    with torch.no_grad():\n",
    "        _ = model([image])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "time_per_image_cpu = elapsed_time / TIMING_RUNS\n",
    "fps_cpu = 1 / time_per_image_cpu\n",
    "\n",
    "print(f\"\\n✓ CPU Timing Complete\")\n",
    "print(f\"  Total time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"  Time per image: {time_per_image_cpu*1000:.2f} ms\")\n",
    "print(f\"  FPS: {fps_cpu:.2f}\")\n",
    "\n",
    "cpu_results = {\n",
    "    'time_ms': time_per_image_cpu * 1000,\n",
    "    'fps': fps_cpu,\n",
    "    'total_time': elapsed_time\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065128c",
   "metadata": {},
   "source": [
    "## 7. mAP Computation Time (Subset)\n",
    "\n",
    "This measures the full evaluation loop including:\n",
    "- Inference\n",
    "- Matching predictions to ground truth\n",
    "- IoU computation\n",
    "- mAP calculation\n",
    "\n",
    "**Note:** This runs on the full subset (not just one image like inference timing above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6813f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.trainer import Trainer\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"mAP COMPUTATION TIME (Subset)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nEvaluating on {len(val_subset)} images...\\n\")\n",
    "\n",
    "# Move model to best available device\n",
    "eval_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(eval_device)\n",
    "\n",
    "# Create a temporary trainer just for evaluation\n",
    "# We don't need optimizer or training setup, just the compute_map method\n",
    "temp_trainer = Trainer(\n",
    "    train_dataset=val_subset,  # Dummy, not used\n",
    "    val_dataset=val_subset,\n",
    "    model=model,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    device=eval_device\n",
    ")\n",
    "\n",
    "# Time the full evaluation\n",
    "start_time = time.time()\n",
    "map_score, mean_iou = temp_trainer.compute_map(\n",
    "    val_loader,\n",
    "    iou_threshold=0.5,\n",
    "    score_threshold=0.5,\n",
    "    max_samples=len(val_subset)  # Evaluate all subset images\n",
    ")\n",
    "eval_time_subset = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Evaluation Complete\")\n",
    "print(f\"  Total time: {eval_time_subset:.2f} seconds ({eval_time_subset/60:.2f} minutes)\")\n",
    "print(f\"  Time per image: {eval_time_subset/len(val_subset)*1000:.2f} ms\")\n",
    "print(f\"  Images per second: {len(val_subset)/eval_time_subset:.2f}\")\n",
    "print(f\"\\n  mAP@0.5: {map_score:.4f}\")\n",
    "print(f\"  Mean IoU: {mean_iou:.4f}\")\n",
    "\n",
    "subset_eval_results = {\n",
    "    'num_images': len(val_subset),\n",
    "    'total_time_sec': eval_time_subset,\n",
    "    'time_per_image_ms': eval_time_subset / len(val_subset) * 1000,\n",
    "    'images_per_sec': len(val_subset) / eval_time_subset,\n",
    "    'map_50': map_score,\n",
    "    'mean_iou': mean_iou\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99324875",
   "metadata": {},
   "source": [
    "## 8. Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INFERENCE TIMING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Inference timing table\n",
    "print(\"\\n### Inference Time\\n\")\n",
    "print(\"| Device | Time per Image (ms) | FPS   | Speedup |\")\n",
    "print(\"| ------ | ------------------- | ----- | ------- |\")\n",
    "\n",
    "if gpu_results:\n",
    "    print(f\"| GPU    | {gpu_results['time_ms']:>19.2f} | {gpu_results['fps']:>5.2f} | 1.00x   |\")\n",
    "    speedup = cpu_results['time_ms'] / gpu_results['time_ms']\n",
    "    print(f\"| CPU    | {cpu_results['time_ms']:>19.2f} | {cpu_results['fps']:>5.2f} | {speedup:>6.2f}x |\")\n",
    "else:\n",
    "    print(f\"| CPU    | {cpu_results['time_ms']:>19.2f} | {cpu_results['fps']:>5.2f} | N/A     |\")\n",
    "\n",
    "# mAP computation time table\n",
    "print(\"\\n### mAP Computation Time\\n\")\n",
    "print(\"| Metric                    | Value          |\")\n",
    "print(\"| ------------------------- | -------------- |\")\n",
    "print(f\"| Evaluation subset size    | {subset_eval_results['num_images']} images     |\")\n",
    "print(f\"| Total evaluation time     | {subset_eval_results['total_time_sec']:.2f} seconds   |\")\n",
    "print(f\"| Time per image            | {subset_eval_results['time_per_image_ms']:.2f} ms        |\")\n",
    "print(f\"| Images per second         | {subset_eval_results['images_per_sec']:.2f}           |\")\n",
    "print(f\"| mAP@0.5                   | {subset_eval_results['map_50']:.4f}         |\")\n",
    "print(f\"| Mean IoU                  | {subset_eval_results['mean_iou']:.4f}         |\")\n",
    "\n",
    "# Notes\n",
    "print(\"\\n### Notes\\n\")\n",
    "print(\"- **Inference time**: Pure model forward pass (batch=1, no NMS overhead)\")\n",
    "print(\"- **mAP computation time**: Full evaluation including matching, IoU, and metric calculation\")\n",
    "print(\"- **Subset evaluation**: Measured on {0} images for practical timing\".format(subset_eval_results['num_images']))\n",
    "if gpu_results:\n",
    "    print(f\"- **GPU speedup**: CPU is {speedup:.1f}x slower than GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a8058",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f910d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = project_root / \"analysis_results\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare export data\n",
    "export_data = {\n",
    "    'timing_config': {\n",
    "        'warmup_runs': WARMUP_RUNS,\n",
    "        'timing_runs': TIMING_RUNS,\n",
    "        'eval_subset_size': EVAL_SUBSET_SIZE,\n",
    "        'image_shape': list(single_image.shape),\n",
    "    },\n",
    "    'inference_timing': {\n",
    "        'gpu': gpu_results if gpu_results else 'Not available',\n",
    "        'cpu': cpu_results,\n",
    "    },\n",
    "    'map_computation': subset_eval_results,\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "output_file = output_dir / \"inference_timing.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Timing results saved to: {output_file}\")\n",
    "\n",
    "# Create summary CSV\n",
    "timing_data = []\n",
    "if gpu_results:\n",
    "    timing_data.append({\n",
    "        'Device': 'GPU',\n",
    "        'Time_per_Image_ms': f\"{gpu_results['time_ms']:.2f}\",\n",
    "        'FPS': f\"{gpu_results['fps']:.2f}\"\n",
    "    })\n",
    "timing_data.append({\n",
    "    'Device': 'CPU',\n",
    "    'Time_per_Image_ms': f\"{cpu_results['time_ms']:.2f}\",\n",
    "    'FPS': f\"{cpu_results['fps']:.2f}\"\n",
    "})\n",
    "\n",
    "timing_df = pd.DataFrame(timing_data)\n",
    "timing_df.to_csv(output_dir / \"inference_timing.csv\", index=False)\n",
    "print(f\"✓ Timing summary saved to: {output_dir / 'inference_timing.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
