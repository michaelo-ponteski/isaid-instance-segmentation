{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a147ff",
   "metadata": {},
   "source": [
    "# Training with Pretrained ResNet Backbones (W&B Integration)\n",
    "\n",
    "This notebook demonstrates iSAID instance segmentation training using **pretrained ResNet-50/ResNet-101** backbones with FPN from torchvision, instead of our custom EfficientNet + CBAM backbone.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "- Uses torchvision's pretrained ResNet-50-FPN or ResNet-101-FPN Mask R-CNN\n",
    "- Automatic logging of training/validation losses and metrics\n",
    "- Learning rate scheduling (OneCycleLR or ReduceLROnPlateau)\n",
    "- Validation predictions visualization\n",
    "- Model checkpointing as W&B artifacts\n",
    "- mAP, mean IoU, and overfitting gap metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4d5f9",
   "metadata": {},
   "source": [
    "## 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aae81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/michaelo-ponteski/isaid-instance-segmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/isaid-instance-segmentation\n",
    "!git pull\n",
    "!git switch wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62870855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Set memory optimization for CUDA\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wandb if not available\n",
    "try:\n",
    "    import wandb\n",
    "    print(f\"wandb version: {wandb.__version__}\") # Must be newest\n",
    "except ImportError:\n",
    "    print(\"Installing wandb...\")\n",
    "    !pip install --upgrade wandb\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232354fa",
   "metadata": {},
   "source": [
    "### Kaggle wandb API setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve the key securely\n",
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb_key\")\n",
    "\n",
    "# 2. Login explicitly (bypasses the interactive freeze)\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import datasets.isaid_dataset\n",
    "import training.transforms\n",
    "import training.trainer\n",
    "\n",
    "importlib.reload(datasets.isaid_dataset)\n",
    "importlib.reload(training.transforms)\n",
    "importlib.reload(training.trainer)\n",
    "\n",
    "from datasets.isaid_dataset import iSAIDDataset\n",
    "from training.transforms import get_transforms\n",
    "from training.trainer import Trainer, create_datasets\n",
    "from training.wandb_logger import ISAID_CLASS_LABELS\n",
    "\n",
    "# Import torchvision's pretrained Mask R-CNN models\n",
    "from torchvision.models.detection import (\n",
    "    maskrcnn_resnet50_fpn,\n",
    "    maskrcnn_resnet50_fpn_v2,\n",
    "    MaskRCNN_ResNet50_FPN_Weights,\n",
    "    MaskRCNN_ResNet50_FPN_V2_Weights,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "print(\"All modules imported successfully!\")\n",
    "print(f\"\\niSAID Class Labels:\")\n",
    "for idx, name in ISAID_CLASS_LABELS.items():\n",
    "    print(f\"  {idx}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a3fdb",
   "metadata": {},
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose backbone: \"resnet50\" or \"resnet101\"\n",
    "# Note: torchvision provides resnet50_fpn pretrained, for resnet101 we build it manually\n",
    "BACKBONE_CHOICE = \"resnet50\"  # Options: \"resnet50\", \"resnet50_v2\", \"resnet101\"\n",
    "\n",
    "# All hyperparameters in one place - this will be logged to W&B\n",
    "HYPERPARAMETERS = {\n",
    "    # Dataset\n",
    "    \"data_root\": \"/kaggle/input/isaid-patches/iSAID_patches\",\n",
    "    \"num_classes\": 16,\n",
    "    \"image_size\": 800,\n",
    "    # Training\n",
    "    \"batch_size\": 2,\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "    # Model Architecture\n",
    "    \"backbone\": BACKBONE_CHOICE,\n",
    "    \"pretrained_backbone\": True,\n",
    "    \"pretrained_coco\": True,  # Use COCO pretrained weights\n",
    "    # RPN Anchors (optimized for iSAID)\n",
    "    \"anchor_sizes\": ((8, 16), (16, 32), (32, 64), (64, 128), (128, 256)),\n",
    "    \"aspect_ratios\": ((0.5, 1.0, 2.0),) * 5,\n",
    "    # W&B Logging\n",
    "    \"wandb_project\": \"isaid-custom-segmentation\",\n",
    "    \"wandb_entity\": \"marek-olnk-put-pozna-\",\n",
    "    \"wandb_log_freq\": 20,  # Log every N batches\n",
    "    \"wandb_num_val_images\": 4,  # Number of images for validation visualization\n",
    "    \"wandb_conf_threshold\": 0.5,  # Confidence threshold for predictions\n",
    "}\n",
    "\n",
    "print(\"Hyperparameters:\")\n",
    "for k, v in HYPERPARAMETERS.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2e51c",
   "metadata": {},
   "source": [
    "## 3. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset, val_dataset = create_datasets(\n",
    "    data_root=HYPERPARAMETERS[\"data_root\"],\n",
    "    image_size=HYPERPARAMETERS[\"image_size\"],\n",
    "    subset_fraction=1.0,  # Use full dataset\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5672c8",
   "metadata": {},
   "source": [
    "## 4. Create Model with Pretrained ResNet Backbone\n",
    "\n",
    "We use torchvision's pretrained Mask R-CNN models and modify the prediction heads for our number of classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8787fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maskrcnn_resnet(num_classes, backbone_type=\"resnet50\", pretrained_coco=True):\n",
    "    \"\"\"\n",
    "    Create Mask R-CNN with pretrained ResNet backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of classes (including background)\n",
    "        backbone_type: \"resnet50\", \"resnet50_v2\", or \"resnet101\"\n",
    "        pretrained_coco: Whether to use COCO pretrained weights\n",
    "\n",
    "    Returns:\n",
    "        Mask R-CNN model\n",
    "    \"\"\"\n",
    "    if backbone_type == \"resnet50\":\n",
    "        # ResNet-50 FPN (original)\n",
    "        if pretrained_coco:\n",
    "            weights = MaskRCNN_ResNet50_FPN_Weights.COCO_V1\n",
    "            model = maskrcnn_resnet50_fpn(weights=weights)\n",
    "        else:\n",
    "            model = maskrcnn_resnet50_fpn(\n",
    "                weights=None, weights_backbone=\"IMAGENET1K_V1\"\n",
    "            )\n",
    "\n",
    "    elif backbone_type == \"resnet50_v2\":\n",
    "        # ResNet-50 FPN V2 (improved, better performance)\n",
    "        if pretrained_coco:\n",
    "            weights = MaskRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "            model = maskrcnn_resnet50_fpn_v2(weights=weights)\n",
    "        else:\n",
    "            model = maskrcnn_resnet50_fpn_v2(\n",
    "                weights=None, weights_backbone=\"IMAGENET1K_V1\"\n",
    "            )\n",
    "\n",
    "    elif backbone_type == \"resnet101\":\n",
    "        # ResNet-101 FPN - build manually using backbone_resnet with resnet101\n",
    "        from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "        from torchvision.models.detection import MaskRCNN\n",
    "        from torchvision.models import ResNet101_Weights\n",
    "\n",
    "        # Create ResNet-101 FPN backbone\n",
    "        backbone = resnet_fpn_backbone(\n",
    "            backbone_name=\"resnet101\",\n",
    "            weights=ResNet101_Weights.IMAGENET1K_V1 if pretrained_coco else None,\n",
    "            trainable_layers=5,  # Train all layers\n",
    "        )\n",
    "\n",
    "        # Create Mask R-CNN with ResNet-101 backbone\n",
    "        model = MaskRCNN(\n",
    "            backbone,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        return model  # Already has correct num_classes\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown backbone type: {backbone_type}. Use 'resnet50', 'resnet50_v2', or 'resnet101'\"\n",
    "        )\n",
    "\n",
    "    # For resnet50/resnet50_v2: Replace the pre-trained head with a new one for our num_classes\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Replace the box predictor\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Replace the mask predictor\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask, hidden_layer, num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = create_maskrcnn_resnet(\n",
    "    num_classes=HYPERPARAMETERS[\"num_classes\"],\n",
    "    backbone_type=HYPERPARAMETERS[\"backbone\"],\n",
    "    pretrained_coco=HYPERPARAMETERS[\"pretrained_coco\"],\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Backbone: {HYPERPARAMETERS['backbone']}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1e6:.1f} MB (FP32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c65ef8",
   "metadata": {},
   "source": [
    "## 5. Create Trainer with W&B Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer with W&B integration\n",
    "# The trainer handles all logging automatically!\n",
    "trainer = Trainer(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    model=model,\n",
    "    batch_size=HYPERPARAMETERS[\"batch_size\"],\n",
    "    lr=HYPERPARAMETERS[\"learning_rate\"],\n",
    "    device=device,\n",
    "    use_amp=True,\n",
    "    num_workers=4,\n",
    "    # W&B configuration\n",
    "    wandb_project=HYPERPARAMETERS[\"wandb_project\"],\n",
    "    wandb_entity=HYPERPARAMETERS[\"wandb_entity\"],\n",
    "    wandb_tags=[\n",
    "        \"maskrcnn\",\n",
    "        HYPERPARAMETERS[\"backbone\"],\n",
    "        \"pretrained\",\n",
    "        \"trainer-integrated\",\n",
    "    ],\n",
    "    wandb_notes=f\"Training with {HYPERPARAMETERS['backbone']} backbone (COCO pretrained) + FPN\",\n",
    "    wandb_log_freq=HYPERPARAMETERS[\"wandb_log_freq\"],\n",
    "    wandb_num_val_images=HYPERPARAMETERS[\"wandb_num_val_images\"],\n",
    "    wandb_conf_threshold=HYPERPARAMETERS[\"wandb_conf_threshold\"],\n",
    "    hyperparameters=HYPERPARAMETERS,\n",
    ")\n",
    "\n",
    "print(f\"\\nW&B Run: {trainer.wandb_logger.run.name}\")\n",
    "print(f\"URL: {trainer.wandb_logger.run.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a053be",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "\n",
    "The `Trainer.fit()` method handles everything:\n",
    "\n",
    "- Training loop with gradient clipping and AMP\n",
    "- Validation loss computation\n",
    "- mAP and mean IoU metrics\n",
    "- W&B logging (losses, gradients, predictions, checkpoints)\n",
    "- Learning rate scheduling\n",
    "- Best model saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97299b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training!\n",
    "# All W&B logging happens automatically inside trainer.fit()\n",
    "history = trainer.fit(\n",
    "    epochs=HYPERPARAMETERS[\"num_epochs\"],\n",
    "    save_dir=\"checkpoints\",\n",
    "    compute_metrics_every=1,  # Compute mAP every epoch\n",
    "    max_map_samples=200,  # Limit samples for faster mAP computation\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create artifact for the final trained model\n",
    "artifact = wandb.Artifact(\n",
    "    name=f\"isaid-maskrcnn-{HYPERPARAMETERS['backbone']}-final\",\n",
    "    type=\"model\",\n",
    "    description=f\"Final trained Mask R-CNN ({HYPERPARAMETERS['backbone']}) after {HYPERPARAMETERS['num_epochs']} epochs\",\n",
    "    metadata={\n",
    "        \"backbone\": HYPERPARAMETERS[\"backbone\"],\n",
    "        \"num_classes\": HYPERPARAMETERS[\"num_classes\"],\n",
    "        \"pretrained_coco\": HYPERPARAMETERS[\"pretrained_coco\"],\n",
    "        \"final_train_loss\": history[\"train/loss\"][-1],\n",
    "        \"final_val_loss\": history[\"val/loss\"][-1],\n",
    "        \"final_val_mAP\": history[\"val/mAP@0.5\"][-1],\n",
    "        \"best_val_mAP\": max(history[\"val/mAP@0.5\"]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add model checkpoint files\n",
    "artifact.add_file(\"checkpoints/best.pth\", name=\"best_model.pth\")\n",
    "artifact.add_file(\"checkpoints/best_map.pth\", name=\"best_map_model.pth\")\n",
    "artifact.add_file(\"checkpoints/last.pth\", name=\"last_model.pth\")\n",
    "\n",
    "# Log the artifact\n",
    "trainer.wandb_logger.run.log_artifact(artifact)\n",
    "\n",
    "print(f\"Model artifacts saved to W&B!\")\n",
    "print(f\"  - best_model.pth (lowest val loss)\")\n",
    "print(f\"  - best_map_model.pth (highest val mAP)\")\n",
    "print(f\"  - last_model.pth (final epoch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e28c9b",
   "metadata": {},
   "source": [
    "## 7. Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cff6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history[\"train/loss\"], label=\"Train Loss\")\n",
    "ax.plot(history[\"val/loss\"], label=\"Val Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training & Validation Loss\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# mAP curves\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history[\"train/mAP@0.5\"], label=\"Train mAP@0.5\")\n",
    "ax.plot(history[\"val/mAP@0.5\"], label=\"Val mAP@0.5\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"mAP@0.5\")\n",
    "ax.set_title(\"mAP Performance\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history[\"train/lr\"])\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Learning Rate\")\n",
    "ax.set_title(\"Learning Rate Schedule\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Gradient norm\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history[\"train/grad_norm\"])\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Gradient Norm\")\n",
    "ax.set_title(\"Training Gradient Norm\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acc1bb",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on validation set\n",
    "trainer.visualize_predictions(\n",
    "    num_samples=5,\n",
    "    score_threshold=0.5,\n",
    "    mask_alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8d21f",
   "metadata": {},
   "source": [
    "## 9. Finish W&B Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the W&B run\n",
    "trainer.finish()\n",
    "\n",
    "print(f\"\\nW&B run completed!\")\n",
    "print(f\"View results at: {trainer.wandb_logger.run.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84608e2b",
   "metadata": {},
   "source": [
    "## 10. Load Model from W&B Artifact (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load best model from W&B artifacts\n",
    "# Uncomment to use\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# artifact = api.artifact('YOUR_ENTITY/isaid-resnet-segmentation/isaid-model:best')\n",
    "# artifact_dir = artifact.download()\n",
    "#\n",
    "# # Recreate model with same architecture\n",
    "# model = create_maskrcnn_resnet(num_classes=16, backbone_type=\"resnet50\")\n",
    "# model.load_state_dict(torch.load(f\"{artifact_dir}/best_model.pth\"))\n",
    "# model.eval()\n",
    "# print(\"Model loaded from W&B artifact!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
