{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e39beb",
   "metadata": {},
   "source": [
    "# Dataset Analysis: Box Count Distribution & Outlier Identification\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook provides **offline, pre-training** analysis of the iSAID dataset to:\n",
    "\n",
    "1. **Understand box-count distribution** per image across train and validation splits\n",
    "2. **Identify outlier images** with unusually high numbers of bounding boxes\n",
    "3. **Visualize** the distribution and most extreme samples\n",
    "\n",
    "## Why This Analysis Matters\n",
    "\n",
    "### Performance Impact of High Box-Count Images\n",
    "\n",
    "Images with many bounding boxes can cause:\n",
    "\n",
    "- **Memory spikes**: Each box generates proposals in the RPN, and the ROI head processes\n",
    "  features for each detected region. Images with 100+ boxes can require 10x more GPU memory\n",
    "  than images with 10 boxes.\n",
    "\n",
    "- **Slow batches**: Training time per batch is dominated by the image with the most boxes.\n",
    "  A batch containing one extreme outlier (e.g., 500 boxes) will be much slower than\n",
    "  a batch of typical images (10-30 boxes).\n",
    "\n",
    "- **Training instability**: Very dense images may produce noisy gradients, especially\n",
    "  if they represent unusual scenes (e.g., parking lots with 200+ cars).\n",
    "\n",
    "### Why Analyze Offline (Not During Training)\n",
    "\n",
    "- **No runtime overhead**: Dataset analysis during training adds latency to every epoch.\n",
    "- **Informed decisions**: Review outliers manually before deciding whether to exclude them.\n",
    "- **Reproducibility**: Document which images are outliers without automatically modifying\n",
    "  the training set.\n",
    "\n",
    "---\n",
    "\n",
    "**Important**: This notebook is **diagnostic only**. It does NOT automatically remove\n",
    "or filter any images. The decision to exclude outliers is left to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3d6c2",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the path to your iSAID dataset and configure analysis parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATA_ROOT = project_root / \"iSAID_patches\"\n",
    "\n",
    "# Analysis parameters\n",
    "TOP_N_OUTLIERS = 100  # Number of top outliers to identify\n",
    "EXPORT_RESULTS = True  # Whether to export results to CSV/JSON\n",
    "OUTPUT_DIR = project_root / \"analysis_results\"\n",
    "\n",
    "# Verify dataset exists\n",
    "assert DATA_ROOT.exists(), f\"Dataset not found at {DATA_ROOT}\"\n",
    "print(f\"Dataset path: {DATA_ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf30924",
   "metadata": {},
   "source": [
    "## 2. Load Annotation Files\n",
    "\n",
    "Load the COCO-format annotation files for train and validation splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(data_root: Path, split: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load COCO-format annotations for a given split.\n",
    "\n",
    "    Args:\n",
    "        data_root: Path to iSAID_patches directory\n",
    "        split: 'train' or 'val'\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing annotations\n",
    "    \"\"\"\n",
    "    ann_file = data_root / split / f\"instances_only_filtered_{split}.json\"\n",
    "\n",
    "    if not ann_file.exists():\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {ann_file}\")\n",
    "\n",
    "    print(f\"Loading {split} annotations from {ann_file}...\")\n",
    "    with open(ann_file, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    print(f\"  - Images: {len(annotations['images'])}\")\n",
    "    print(f\"  - Annotations: {len(annotations['annotations'])}\")\n",
    "    print(f\"  - Categories: {len(annotations['categories'])}\")\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# Load annotations for both splits\n",
    "train_anns = load_annotations(DATA_ROOT, \"train\")\n",
    "val_anns = load_annotations(DATA_ROOT, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80bb70",
   "metadata": {},
   "source": [
    "## 3. Count Bounding Boxes Per Image\n",
    "\n",
    "Iterate over all annotations and count boxes per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_boxes_per_image(annotations: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count the number of bounding boxes per image.\n",
    "\n",
    "    Args:\n",
    "        annotations: COCO-format annotations dictionary\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: image_id, file_name, num_boxes, width, height\n",
    "    \"\"\"\n",
    "    # Create image_id to info mapping\n",
    "    img_info = {img[\"id\"]: img for img in annotations[\"images\"]}\n",
    "\n",
    "    # Count boxes per image\n",
    "    box_counts = Counter()\n",
    "    for ann in annotations[\"annotations\"]:\n",
    "        box_counts[ann[\"image_id\"]] += 1\n",
    "\n",
    "    # Build DataFrame with all images (including those with 0 boxes)\n",
    "    records = []\n",
    "    for img in annotations[\"images\"]:\n",
    "        img_id = img[\"id\"]\n",
    "        records.append(\n",
    "            {\n",
    "                \"image_id\": img_id,\n",
    "                \"file_name\": img[\"file_name\"],\n",
    "                \"num_boxes\": box_counts.get(img_id, 0),\n",
    "                \"width\": img.get(\"width\", 0),\n",
    "                \"height\": img.get(\"height\", 0),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df = df.sort_values(\"num_boxes\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Count boxes for both splits\n",
    "train_box_counts = count_boxes_per_image(train_anns)\n",
    "val_box_counts = count_boxes_per_image(val_anns)\n",
    "\n",
    "print(f\"\\nTrain split: {len(train_box_counts)} images\")\n",
    "print(f\"Val split: {len(val_box_counts)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58434f25",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary\n",
    "\n",
    "Compute and display statistics for box counts in each split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19101f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(df: pd.DataFrame, split_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compute statistics for box counts.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'num_boxes' column\n",
    "        split_name: Name of the split for display\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of statistics\n",
    "    \"\"\"\n",
    "    box_counts = df[\"num_boxes\"]\n",
    "\n",
    "    stats = {\n",
    "        \"Split\": split_name,\n",
    "        \"Total Images\": len(df),\n",
    "        \"Total Boxes\": box_counts.sum(),\n",
    "        \"Min\": box_counts.min(),\n",
    "        \"Max\": box_counts.max(),\n",
    "        \"Mean\": box_counts.mean(),\n",
    "        \"Median\": box_counts.median(),\n",
    "        \"Std\": box_counts.std(),\n",
    "        \"Q25 (25th percentile)\": box_counts.quantile(0.25),\n",
    "        \"Q75 (75th percentile)\": box_counts.quantile(0.75),\n",
    "        \"Q90 (90th percentile)\": box_counts.quantile(0.90),\n",
    "        \"Q95 (95th percentile)\": box_counts.quantile(0.95),\n",
    "        \"Q99 (99th percentile)\": box_counts.quantile(0.99),\n",
    "        \"Images with 0 boxes\": (box_counts == 0).sum(),\n",
    "        \"Images with >50 boxes\": (box_counts > 50).sum(),\n",
    "        \"Images with >100 boxes\": (box_counts > 100).sum(),\n",
    "        \"Images with >200 boxes\": (box_counts > 200).sum(),\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Compute statistics for both splits\n",
    "train_stats = compute_statistics(train_box_counts, \"Train\")\n",
    "val_stats = compute_statistics(val_box_counts, \"Validation\")\n",
    "\n",
    "# Display as DataFrame for easy comparison\n",
    "stats_df = pd.DataFrame([train_stats, val_stats]).set_index(\"Split\").T\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BOX COUNT STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c1720",
   "metadata": {},
   "source": [
    "## 5. Distribution Visualization\n",
    "\n",
    "Visualize the distribution of box counts per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training set histogram\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(\n",
    "    train_box_counts[\"num_boxes\"],\n",
    "    bins=50,\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "ax1.axvline(\n",
    "    train_box_counts[\"num_boxes\"].mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {train_box_counts['num_boxes'].mean():.1f}\",\n",
    ")\n",
    "ax1.axvline(\n",
    "    train_box_counts[\"num_boxes\"].median(),\n",
    "    color=\"orange\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {train_box_counts['num_boxes'].median():.1f}\",\n",
    ")\n",
    "ax1.set_xlabel(\"Number of Boxes per Image\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.set_title(\"Train Set: Box Count Distribution\")\n",
    "ax1.legend()\n",
    "\n",
    "# Validation set histogram\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(\n",
    "    val_box_counts[\"num_boxes\"], bins=50, edgecolor=\"black\", alpha=0.7, color=\"seagreen\"\n",
    ")\n",
    "ax2.axvline(\n",
    "    val_box_counts[\"num_boxes\"].mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {val_box_counts['num_boxes'].mean():.1f}\",\n",
    ")\n",
    "ax2.axvline(\n",
    "    val_box_counts[\"num_boxes\"].median(),\n",
    "    color=\"orange\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {val_box_counts['num_boxes'].median():.1f}\",\n",
    ")\n",
    "ax2.set_xlabel(\"Number of Boxes per Image\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.set_title(\"Validation Set: Box Count Distribution\")\n",
    "ax2.legend()\n",
    "\n",
    "# Log-scale histogram (combined)\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(\n",
    "    train_box_counts[\"num_boxes\"], bins=50, alpha=0.6, label=\"Train\", color=\"steelblue\"\n",
    ")\n",
    "ax3.hist(\n",
    "    val_box_counts[\"num_boxes\"],\n",
    "    bins=50,\n",
    "    alpha=0.6,\n",
    "    label=\"Validation\",\n",
    "    color=\"seagreen\",\n",
    ")\n",
    "ax3.set_xlabel(\"Number of Boxes per Image\")\n",
    "ax3.set_ylabel(\"Frequency (log scale)\")\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.set_title(\"Combined Distribution (Log Scale)\")\n",
    "ax3.legend()\n",
    "\n",
    "# Box plot comparison\n",
    "ax4 = axes[1, 1]\n",
    "combined_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Split\": [\"Train\"] * len(train_box_counts)\n",
    "        + [\"Validation\"] * len(val_box_counts),\n",
    "        \"Box Count\": list(train_box_counts[\"num_boxes\"])\n",
    "        + list(val_box_counts[\"num_boxes\"]),\n",
    "    }\n",
    ")\n",
    "sns.boxplot(\n",
    "    data=combined_data,\n",
    "    x=\"Split\",\n",
    "    y=\"Box Count\",\n",
    "    ax=ax4,\n",
    "    palette=[\"steelblue\", \"seagreen\"],\n",
    ")\n",
    "ax4.set_title(\"Box Count Distribution by Split\")\n",
    "\n",
    "plt.tight_layout()\n",
    "(\n",
    "    plt.savefig(OUTPUT_DIR / \"box_count_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    if EXPORT_RESULTS\n",
    "    else None\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df2d8a",
   "metadata": {},
   "source": [
    "## 6. Outlier Identification\n",
    "\n",
    "Identify the top N images with the highest number of bounding boxes.\n",
    "\n",
    "### Why These Images May Cause Issues\n",
    "\n",
    "- **GPU Memory**: Each box generates anchors, proposals, and ROI features. Images with\n",
    "  300+ boxes may require 5-10GB extra GPU memory compared to typical images.\n",
    "- **Batch Time**: With batch_size=4, if one image has 500 boxes while others have 20,\n",
    "  the forward pass time is dominated by the 500-box image.\n",
    "- **Gradient Noise**: Very dense images may not be representative of test distribution,\n",
    "  potentially degrading model generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_outliers(df: pd.DataFrame, top_n: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the top N images with the most bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with box counts\n",
    "        top_n: Number of outliers to return\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with top outliers\n",
    "    \"\"\"\n",
    "    return df.head(top_n).copy()\n",
    "\n",
    "\n",
    "# Get top outliers for both splits\n",
    "train_outliers = get_top_outliers(train_box_counts, TOP_N_OUTLIERS)\n",
    "val_outliers = get_top_outliers(val_box_counts, TOP_N_OUTLIERS)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TOP {TOP_N_OUTLIERS} TRAIN IMAGES (HIGHEST BOX COUNTS)\")\n",
    "print(\"=\" * 60)\n",
    "display(train_outliers.head(20))  # Show first 20\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TOP {TOP_N_OUTLIERS} VALIDATION IMAGES (HIGHEST BOX COUNTS)\")\n",
    "print(\"=\" * 60)\n",
    "display(val_outliers.head(20))  # Show first 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e80751",
   "metadata": {},
   "source": [
    "## 7. Bar Plot of Top Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_outliers(df: pd.DataFrame, top_n: int = 30, title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Create a bar plot of top N outliers by box count.\n",
    "    \"\"\"\n",
    "    top_df = df.head(top_n)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    bars = ax.barh(\n",
    "        range(len(top_df)),\n",
    "        top_df[\"num_boxes\"],\n",
    "        color=\"coral\",\n",
    "        edgecolor=\"darkred\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (v, name) in enumerate(zip(top_df[\"num_boxes\"], top_df[\"file_name\"])):\n",
    "        ax.text(v + 2, i, f\"{v}\", va=\"center\", fontsize=8)\n",
    "\n",
    "    ax.set_yticks(range(len(top_df)))\n",
    "    ax.set_yticklabels(\n",
    "        [f[:30] + \"...\" if len(f) > 30 else f for f in top_df[\"file_name\"]], fontsize=8\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Number of Bounding Boxes\")\n",
    "    ax.set_ylabel(\"Image File\")\n",
    "    ax.set_title(title)\n",
    "    ax.axvline(\n",
    "        df[\"num_boxes\"].mean(),\n",
    "        color=\"blue\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.7,\n",
    "        label=f'Mean: {df[\"num_boxes\"].mean():.1f}',\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Plot top 30 outliers for each split\n",
    "fig1 = plot_top_outliers(\n",
    "    train_box_counts, top_n=30, title=\"Train Set: Top 30 Images by Box Count\"\n",
    ")\n",
    "if EXPORT_RESULTS:\n",
    "    fig1.savefig(OUTPUT_DIR / \"train_top_outliers.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_top_outliers(\n",
    "    val_box_counts, top_n=30, title=\"Validation Set: Top 30 Images by Box Count\"\n",
    ")\n",
    "if EXPORT_RESULTS:\n",
    "    fig2.savefig(OUTPUT_DIR / \"val_top_outliers.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d767aa",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Save outlier lists and statistics for future reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad90f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_RESULTS:\n",
    "    # Create output directory\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Export train outliers\n",
    "    train_outliers_path = OUTPUT_DIR / \"train_outliers_top100.csv\"\n",
    "    train_outliers.to_csv(train_outliers_path, index=False)\n",
    "    print(f\"Saved train outliers to: {train_outliers_path}\")\n",
    "\n",
    "    # Export validation outliers\n",
    "    val_outliers_path = OUTPUT_DIR / \"val_outliers_top100.csv\"\n",
    "    val_outliers.to_csv(val_outliers_path, index=False)\n",
    "    print(f\"Saved validation outliers to: {val_outliers_path}\")\n",
    "\n",
    "    # Export full box counts\n",
    "    train_box_counts.to_csv(OUTPUT_DIR / \"train_all_box_counts.csv\", index=False)\n",
    "    val_box_counts.to_csv(OUTPUT_DIR / \"val_all_box_counts.csv\", index=False)\n",
    "    print(f\"Saved full box counts to output directory\")\n",
    "\n",
    "    # Export statistics as JSON\n",
    "    stats_export = {\n",
    "        \"train\": train_stats,\n",
    "        \"validation\": val_stats,\n",
    "    }\n",
    "    with open(OUTPUT_DIR / \"box_count_statistics.json\", \"w\") as f:\n",
    "        json.dump(stats_export, f, indent=2, default=float)\n",
    "    print(f\"Saved statistics to: {OUTPUT_DIR / 'box_count_statistics.json'}\")\n",
    "\n",
    "    print(f\"\\n✓ All results exported to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"Export disabled. Set EXPORT_RESULTS = True to save results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f6987",
   "metadata": {},
   "source": [
    "## 9. Visualize Extreme Outliers (Optional)\n",
    "\n",
    "View a few of the most extreme images with their bounding box overlays.\n",
    "\n",
    "**Note**: This is read-only visualization - no modifications are made to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "def visualize_image_with_boxes(\n",
    "    data_root: Path, split: str, image_info: dict, annotations: dict, figsize=(12, 10)\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize an image with its bounding boxes overlaid.\n",
    "\n",
    "    This is read-only visualization - the dataset is not modified.\n",
    "\n",
    "    Args:\n",
    "        data_root: Path to iSAID_patches\n",
    "        split: 'train' or 'val'\n",
    "        image_info: Dict with 'image_id', 'file_name', 'num_boxes'\n",
    "        annotations: Full annotations dict\n",
    "    \"\"\"\n",
    "    img_path = data_root / split / \"images\" / image_info[\"file_name\"]\n",
    "\n",
    "    if not img_path.exists():\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "    # Get annotations for this image\n",
    "    img_id = image_info[\"image_id\"]\n",
    "    img_anns = [ann for ann in annotations[\"annotations\"] if ann[\"image_id\"] == img_id]\n",
    "\n",
    "    # Draw boxes\n",
    "    img_with_boxes = img.copy()\n",
    "    for ann in img_anns:\n",
    "        x, y, w, h = [int(v) for v in ann[\"bbox\"]]\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(img_with_boxes)\n",
    "    axes[1].set_title(f\"With Boxes (n={image_info['num_boxes']})\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"File: {image_info['file_name']}\\nImage ID: {image_info['image_id']} | Boxes: {image_info['num_boxes']}\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 3 most extreme train images\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VISUALIZING TOP 3 TRAIN OUTLIERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(min(3, len(train_outliers))):\n",
    "    row = train_outliers.iloc[i]\n",
    "    visualize_image_with_boxes(\n",
    "        DATA_ROOT,\n",
    "        \"train\",\n",
    "        {\n",
    "            \"image_id\": row[\"image_id\"],\n",
    "            \"file_name\": row[\"file_name\"],\n",
    "            \"num_boxes\": row[\"num_boxes\"],\n",
    "        },\n",
    "        train_anns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 3 most extreme validation images\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VISUALIZING TOP 3 VALIDATION OUTLIERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(min(3, len(val_outliers))):\n",
    "    row = val_outliers.iloc[i]\n",
    "    visualize_image_with_boxes(\n",
    "        DATA_ROOT,\n",
    "        \"val\",\n",
    "        {\n",
    "            \"image_id\": row[\"image_id\"],\n",
    "            \"file_name\": row[\"file_name\"],\n",
    "            \"num_boxes\": row[\"num_boxes\"],\n",
    "        },\n",
    "        val_anns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a12860",
   "metadata": {},
   "source": [
    "## 10. Summary & Recommendations\n",
    "\n",
    "Based on the analysis above, you may consider the following actions:\n",
    "\n",
    "### Potential Actions (User Decision Required)\n",
    "\n",
    "1. **Do Nothing**: If outliers are few and memory/time is acceptable, keep all images.\n",
    "\n",
    "2. **Exclude Extreme Outliers**: Remove images with >N boxes (e.g., N=200 or N=300)\n",
    "   from training. This can be done by:\n",
    "   - Creating a custom dataset wrapper that filters by image ID\n",
    "   - Or modifying the annotation file to exclude specific images\n",
    "\n",
    "3. **Dynamic Batching**: Use a custom sampler that groups images by box count\n",
    "   to avoid mixing extreme outliers with normal images in the same batch.\n",
    "\n",
    "4. **Increase GPU Memory**: If possible, use a GPU with more VRAM to handle\n",
    "   dense images without OOM errors.\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "If `EXPORT_RESULTS = True`, the following files are created in `analysis_results/`:\n",
    "\n",
    "- `train_outliers_top100.csv`: Top 100 train images with highest box counts\n",
    "- `val_outliers_top100.csv`: Top 100 validation images with highest box counts\n",
    "- `train_all_box_counts.csv`: Full box counts for all train images\n",
    "- `val_all_box_counts.csv`: Full box counts for all validation images\n",
    "- `box_count_statistics.json`: Statistical summary for both splits\n",
    "- `box_count_distribution.png`: Distribution visualization\n",
    "- `train_top_outliers.png`: Bar plot of train outliers\n",
    "- `val_top_outliers.png`: Bar plot of validation outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04069404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  - Total images: {len(train_box_counts)}\")\n",
    "print(\n",
    "    f\"  - Box count range: {train_box_counts['num_boxes'].min()} - {train_box_counts['num_boxes'].max()}\"\n",
    ")\n",
    "print(f\"  - Mean boxes/image: {train_box_counts['num_boxes'].mean():.1f}\")\n",
    "print(f\"  - Images with >100 boxes: {(train_box_counts['num_boxes'] > 100).sum()}\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  - Total images: {len(val_box_counts)}\")\n",
    "print(\n",
    "    f\"  - Box count range: {val_box_counts['num_boxes'].min()} - {val_box_counts['num_boxes'].max()}\"\n",
    ")\n",
    "print(f\"  - Mean boxes/image: {val_box_counts['num_boxes'].mean():.1f}\")\n",
    "print(f\"  - Images with >100 boxes: {(val_box_counts['num_boxes'] > 100).sum()}\")\n",
    "\n",
    "print(f\"\\n⚠️  Remember: This analysis is diagnostic only.\")\n",
    "print(f\"   The decision to exclude outliers is left to the user.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
