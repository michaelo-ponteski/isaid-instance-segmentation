{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5aadee",
   "metadata": {},
   "source": [
    "# Full model pipeline for optimizing anchor sizes for RPN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8e7e0",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook provides a complete pipeline for optimizing RPN anchor sizes using **GEOMETRIC COVERAGE**:\n",
    "1. **Dataset Analysis** - Analyze object sizes and aspect ratios in your dataset\n",
    "2. **Stride-Constrained Suggestions** - Get anchor recommendations respecting FPN constraints\n",
    "3. **Optuna Optimization** - Find optimal anchors using theoretical recall (no training required!)\n",
    "4. **Comparison** - Compare different anchor configurations\n",
    "\n",
    "### Key Insight\n",
    "Anchor optimization should find anchors that **geometrically cover** GT boxes with high IoU.\n",
    "This is 100x faster than training-based optimization and more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24087de3",
   "metadata": {},
   "source": [
    "## 0. Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61014838",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/michaelo-ponteski/isaid-instance-segmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/isaid-instance-segmentation\n",
    "!git pull\n",
    "!git switch mk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e435aa",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32572d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Set memory optimization for CUDA\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install optuna if not available\n",
    "try:\n",
    "    import optuna\n",
    "    print(f\"Optuna version: {optuna.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing optuna...\")\n",
    "    !pip install optuna\n",
    "    import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6278511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import datasets.isaid_dataset\n",
    "import models.maskrcnn_model\n",
    "import utils.overfit_test\n",
    "import training.trainer\n",
    "import training.transforms\n",
    "import training.anchor_optimizer\n",
    "\n",
    "importlib.reload(datasets.isaid_dataset)\n",
    "importlib.reload(models.maskrcnn_model)\n",
    "importlib.reload(utils.overfit_test)\n",
    "importlib.reload(training.trainer)\n",
    "importlib.reload(training.transforms)\n",
    "importlib.reload(training.anchor_optimizer)\n",
    "\n",
    "# Import project modules\n",
    "from datasets.isaid_dataset import iSAIDDataset\n",
    "from training.transforms import get_transforms\n",
    "from training.anchor_optimizer import (\n",
    "    AnchorConfig,\n",
    "    GeometricAnchorOptimizer,  # New: uses geometric recall\n",
    "    DatasetAnchorAnalyzer,\n",
    "    optimize_anchors_for_dataset,\n",
    "    analyze_dataset_anchors,\n",
    "    compare_anchor_configs,\n",
    "    generate_anchors_for_image,\n",
    "    FPN_STRIDES,\n",
    ")\n",
    "from models.maskrcnn_model import CustomMaskRCNN, get_custom_maskrcnn\n",
    "\n",
    "print(\"All modules imported successfully!\")\n",
    "print(f\"FPN Strides: {FPN_STRIDES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63506b4e",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1865bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Dataset\n",
    "    \"data_root\": \"/kaggle/input/isaid-patches/iSAID_patches\",  # Path to dataset\n",
    "    \"num_classes\": 16,                 # 15 classes + background\n",
    "    \"image_size\": 800,                 # Image size for training\n",
    "    \n",
    "    # Anchor Optimization (Geometric - much faster!)\n",
    "    \"n_trials\": 20,                    # Number of Optuna trials\n",
    "    \"num_samples\": 700,                # Samples for geometric recall evaluation\n",
    "    \n",
    "    # FPN Strides (critical for anchor constraints!)\n",
    "    \"strides\": [4, 8, 16, 32],         # P2, P3, P4, P5\n",
    "    \n",
    "    # Output\n",
    "    \"cache_path\": \"/kaggle/working/optimized_anchors.pt\",  # Where to save optimized anchors\n",
    "}\n",
    "\n",
    "# Default stride-based anchor configuration (respects FPN constraints)\n",
    "# Rule: anchor_size >= stride * 2 for effective detection\n",
    "DEFAULT_ANCHORS = AnchorConfig(\n",
    "    sizes=tuple((s*2, s*4) for s in CONFIG[\"strides\"]),  # (8,16), (16,32), (32,64), (64,128)\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),) * 4,\n",
    ")\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\nDefault (stride-based) anchors:\")\n",
    "print(f\"  Sizes: {DEFAULT_ANCHORS.sizes}\")\n",
    "print(f\"  Ratios: {DEFAULT_ANCHORS.aspect_ratios}\")\n",
    "print(f\"\\nNote: Anchor size >= stride*2 for each FPN level!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1e910",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ace62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets (without augmentation for analysis)\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "train_dataset = iSAIDDataset(\n",
    "    CONFIG[\"data_root\"],\n",
    "    split=\"train\",\n",
    "    transforms=get_transforms(train=False),\n",
    "    image_size=CONFIG[\"image_size\"],\n",
    ")\n",
    "\n",
    "val_dataset = iSAIDDataset(\n",
    "    CONFIG[\"data_root\"],\n",
    "    split=\"val\",\n",
    "    transforms=get_transforms(train=False),\n",
    "    image_size=CONFIG[\"image_size\"],\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f8494",
   "metadata": {},
   "source": [
    "## 4. Dataset Analysis\n",
    "\n",
    "First, let's analyze the object sizes and aspect ratios in the dataset to understand what anchor configurations might work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset for bounding box statistics\n",
    "analyzer = DatasetAnchorAnalyzer(train_dataset, num_samples=CONFIG[\"num_analysis_samples\"])\n",
    "stats = analyzer.compute_box_statistics()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Dataset Bounding Box Statistics\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Number of boxes analyzed: {len(stats['widths']):,}\")\n",
    "print(f\"\\nWidth:  min={stats['widths'].min():.1f}, max={stats['widths'].max():.1f}, mean={stats['widths'].mean():.1f}, std={stats['widths'].std():.1f}\")\n",
    "print(f\"Height: min={stats['heights'].min():.1f}, max={stats['heights'].max():.1f}, mean={stats['heights'].mean():.1f}, std={stats['heights'].std():.1f}\")\n",
    "print(f\"Area:   min={stats['areas'].min():.1f}, max={stats['areas'].max():.1f}, mean={stats['areas'].mean():.1f}\")\n",
    "print(f\"Aspect Ratio: min={stats['aspect_ratios'].min():.2f}, max={stats['aspect_ratios'].max():.2f}, mean={stats['aspect_ratios'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2599908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Object scales (sqrt of area)\n",
    "scales = np.sqrt(stats['areas'])\n",
    "axes[0, 0].hist(scales, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 0].axvline(np.median(scales), color='red', linestyle='--', label=f'Median: {np.median(scales):.1f}')\n",
    "axes[0, 0].set_xlabel('Object Scale (âˆšarea)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Object Scales')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Aspect ratios\n",
    "axes[0, 1].hist(stats['aspect_ratios'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[0, 1].axvline(np.median(stats['aspect_ratios']), color='red', linestyle='--', \n",
    "                   label=f'Median: {np.median(stats[\"aspect_ratios\"]):.2f}')\n",
    "axes[0, 1].set_xlabel('Aspect Ratio (w/h)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Aspect Ratios')\n",
    "axes[0, 1].set_xlim(0, 5)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Width vs Height scatter\n",
    "sample_idx = np.random.choice(len(stats['widths']), min(2000, len(stats['widths'])), replace=False)\n",
    "axes[1, 0].scatter(stats['widths'][sample_idx], stats['heights'][sample_idx], alpha=0.3, s=5)\n",
    "axes[1, 0].set_xlabel('Width')\n",
    "axes[1, 0].set_ylabel('Height')\n",
    "axes[1, 0].set_title('Width vs Height (sample)')\n",
    "axes[1, 0].set_aspect('equal')\n",
    "\n",
    "# Scale percentiles (for anchor size selection)\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "scale_percentiles = np.percentile(scales, percentiles)\n",
    "axes[1, 1].barh(range(len(percentiles)), scale_percentiles, color='teal', edgecolor='black')\n",
    "axes[1, 1].set_yticks(range(len(percentiles)))\n",
    "axes[1, 1].set_yticklabels([f'{p}th' for p in percentiles])\n",
    "axes[1, 1].set_xlabel('Object Scale')\n",
    "axes[1, 1].set_title('Scale Percentiles')\n",
    "for i, v in enumerate(scale_percentiles):\n",
    "    axes[1, 1].text(v + 1, i, f'{v:.1f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScale percentiles (useful for anchor sizes):\")\n",
    "for p in [10, 20, 30, 50, 70, 80, 90]:\n",
    "    print(f\"  {p}th percentile: {np.percentile(scales, p):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01366bc7",
   "metadata": {},
   "source": [
    "## 5. Data-Driven Anchor Suggestions\n",
    "\n",
    "Get initial anchor recommendations based on dataset statistics (without Optuna optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stride-constrained suggestions based on data\n",
    "suggested_sizes = analyzer.suggest_anchor_sizes_with_stride_constraints(\n",
    "    strides=CONFIG[\"strides\"]\n",
    ")\n",
    "suggested_ratios = analyzer.suggest_aspect_ratios(num_ratios=3)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STRIDE-CONSTRAINED Anchor Suggestions\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nFPN Level | Stride | Min Valid | Suggested Sizes\")\n",
    "print(\"-\" * 60)\n",
    "for i, (stride, sizes) in enumerate(zip(CONFIG[\"strides\"], suggested_sizes)):\n",
    "    min_valid = stride * 2\n",
    "    print(f\"   P{i+2}    |   {stride:2d}   |    {min_valid:3d}    | {sizes}\")\n",
    "\n",
    "print(f\"\\nSuggested aspect ratios: {suggested_ratios}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Comparison\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Default sizes:    {DEFAULT_ANCHORS.sizes}\")\n",
    "print(f\"Suggested sizes:  {suggested_sizes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04237dbe",
   "metadata": {},
   "source": [
    "## 6. Geometric Anchor Optimization (FAST!)\n",
    "\n",
    "Run Optuna optimization using **geometric recall** (theoretical IoU coverage).\n",
    "\n",
    "This is:\n",
    "- **100x faster** than training-based optimization (no model training!)\n",
    "- **More stable** (no random initialization noise)\n",
    "- **Physically correct** (respects FPN stride constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GEOMETRIC anchor optimizer (no training required!)\n",
    "geo_optimizer = GeometricAnchorOptimizer(\n",
    "    dataset=train_dataset,\n",
    "    image_size=(CONFIG[\"image_size\"], CONFIG[\"image_size\"]),\n",
    "    strides=CONFIG[\"strides\"],\n",
    "    base_aspect_ratios=(0.5, 1.0, 2.0),\n",
    "    num_samples=CONFIG[\"num_samples\"],\n",
    ")\n",
    "\n",
    "print(\"Geometric Optimizer initialized!\")\n",
    "print(f\"Cached {geo_optimizer.total_gt_boxes} GT boxes for fast evaluation\")\n",
    "print(f\"Suggested ratios from data: {geo_optimizer.suggested_ratios}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FAST geometric optimization (no training!)\n",
    "# This should take only 1-2 minutes instead of 30+ minutes\n",
    "print(f\"Starting GEOMETRIC optimization with {CONFIG['n_trials']} trials...\")\n",
    "print(\"This is FAST because it only computes IoU coverage, no model training!\\n\")\n",
    "\n",
    "best_config = geo_optimizer.optimize(\n",
    "    n_trials=CONFIG[\"n_trials\"],\n",
    "    study_name=\"geometric_anchor_optimization\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c61e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimized anchors\n",
    "torch.save({\n",
    "    'sizes': best_config.sizes,\n",
    "    'aspect_ratios': best_config.aspect_ratios,\n",
    "}, CONFIG[\"cache_path\"])\n",
    "\n",
    "print(f\"Optimized anchors saved to: {CONFIG['cache_path']}\")\n",
    "print(f\"\\nBest configuration found:\")\n",
    "print(f\"  Sizes: {best_config.sizes}\")\n",
    "print(f\"  Aspect ratios: {best_config.aspect_ratios}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9651b",
   "metadata": {},
   "source": [
    "## 7. Compare Anchor Configurations\n",
    "\n",
    "Compare geometric recall for different anchor configurations.\n",
    "This shows the **theoretical maximum recall** each configuration can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple anchor configurations using geometric recall\n",
    "configs_to_compare = {\n",
    "    \"Stride Adjusted\": DEFAULT_ANCHORS,\n",
    "    \"Opt 1\": AnchorConfig(\n",
    "        sizes=((12, 24), (64, 96), (48, 144), (64, 480)),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),) * 4,\n",
    "    ),\n",
    "    \"Opt 2\": AnchorConfig(\n",
    "        sizes=((12, 52), (24, 56), (176, 224), (64, 192)),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),) * 4,\n",
    "    ),\n",
    "    \"Opt 3\": AnchorConfig(\n",
    "        sizes=((8, 44), (16, 56), (144, 208), (96, 192)),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),) * 4,\n",
    "    ),\n",
    "    \"Initial guess\": AnchorConfig(\n",
    "        sizes=((16, 24), (32, 48), (64, 96), (128, 192)),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),) * 4,\n",
    "    ),\n",
    "    \"Data-suggested\": AnchorConfig(\n",
    "        sizes=((8, 12), (16, 24), (32, 48), (64, 96)),\n",
    "        aspect_ratios=((np.float64(0.6), np.float64(1.0), np.float64(1.67)),) * 4,\n",
    "    ),\n",
    "    \"Data-suggested (default ratios)\": AnchorConfig(\n",
    "        sizes=((8, 12), (16, 24), (32, 48), (64, 96)),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),) * 4\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GEOMETRIC RECALL COMPARISON\")\n",
    "print(\"(Theoretical maximum recall - no training involved)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_results = compare_anchor_configs(\n",
    "    dataset=train_dataset,\n",
    "    configs=configs_to_compare,\n",
    "    image_size=(CONFIG[\"image_size\"], CONFIG[\"image_size\"]),\n",
    "    num_samples=CONFIG[\"num_samples\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82771c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison - DYNAMIC for any number of configs\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(12, len(configs_to_compare) * 2), 6))\n",
    "\n",
    "config_names = list(comparison_results.keys())\n",
    "metrics = ['recall@0.5', 'recall@0.7', 'recall@0.75']\n",
    "x = np.arange(len(metrics))\n",
    "n_configs = len(config_names)\n",
    "width = 0.8 / n_configs  # Dynamic width based on number of configs\n",
    "\n",
    "# Generate colors dynamically\n",
    "colors = cm.tab10(np.linspace(0, 1, n_configs))\n",
    "\n",
    "for i, (name, results) in enumerate(comparison_results.items()):\n",
    "    vals = [results.get(m, 0) for m in metrics]\n",
    "    offset = (i - n_configs/2 + 0.5) * width\n",
    "    bars = ax.bar(x + offset, vals, width, label=name, color=colors[i], edgecolor='black')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "ax.set_ylabel('Geometric Recall (Theoretical Max)')\n",
    "ax.set_title('Anchor Configuration Comparison\\n(Higher is better - this is the theoretical ceiling)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Recall@0.5', 'Recall@0.7', 'Recall@0.75'])\n",
    "ax.legend(loc='upper right', fontsize=8)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.axhline(y=0.9, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY: Geometric Recall Comparison\")\n",
    "print(f\"{'='*60}\")\n",
    "for name, results in comparison_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for m, v in results.items():\n",
    "        print(f\"  {m}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d603ad",
   "metadata": {},
   "source": [
    "## 8. Visualize Anchor Coverage\n",
    "\n",
    "See how anchors cover the object size distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anchor sizes vs object scale distribution - DYNAMIC\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot object scale histogram\n",
    "scales = np.sqrt(stats['areas'])\n",
    "ax.hist(scales, bins=100, alpha=0.5, color='gray', edgecolor='none', label='Object scales')\n",
    "\n",
    "# Generate colors dynamically for all configs\n",
    "config_names = list(configs_to_compare.keys())\n",
    "n_configs = len(config_names)\n",
    "colors = cm.tab10(np.linspace(0, 1, n_configs))\n",
    "color_map = {name: colors[i] for i, name in enumerate(config_names)}\n",
    "\n",
    "# Plot anchor sizes for each configuration\n",
    "for name, config in configs_to_compare.items():\n",
    "    color = color_map[name]\n",
    "    for level_idx, sizes in enumerate(config.sizes):\n",
    "        for j, size in enumerate(sizes):\n",
    "            # Only add label once per config\n",
    "            label = name if level_idx == 0 and j == 0 else None\n",
    "            ax.axvline(size, color=color, alpha=0.6, linestyle='--', linewidth=1.5, label=label)\n",
    "\n",
    "# Add FPN stride markers\n",
    "for stride in CONFIG[\"strides\"]:\n",
    "    min_anchor = stride * 2\n",
    "    ax.axvline(min_anchor, color='black', alpha=0.3, linestyle=':', linewidth=1)\n",
    "    ax.text(min_anchor + 1, ax.get_ylim()[1] * 0.95, f'min@s={stride}', fontsize=7, rotation=90, va='top')\n",
    "\n",
    "ax.set_xlabel('Object Scale / Anchor Size (pixels)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Object Scale Distribution with Anchor Sizes\\n(Dotted black lines = minimum valid anchor for each FPN stride)')\n",
    "ax.legend(loc='upper right', fontsize=8)\n",
    "ax.set_xlim(0, 300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show all configurations clearly - DYNAMIC\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ANCHOR CONFIGURATION DETAILS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Build header dynamically\n",
    "header = \"FPN Level | Stride | Min Valid\"\n",
    "for name in config_names:\n",
    "    header += f\" | {name[:15]:^15}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i, stride in enumerate(CONFIG[\"strides\"]):\n",
    "    min_valid = stride * 2\n",
    "    row = f\"   P{i+2}    |   {stride:2d}   |    {min_valid:3d}   \"\n",
    "    for name in config_names:\n",
    "        config = configs_to_compare[name]\n",
    "        sizes = config.sizes[i] if i < len(config.sizes) else \"N/A\"\n",
    "        row += f\" | {str(sizes):^15}\"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaad405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del train_dataset, val_dataset, analyzer, geo_optimizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
